{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Note: Some console outputs (print statements) were generated during the initial model runs in Spanish.\n",
    "Since these steps involve computationally expensive models, the notebook\n",
    "is not re-executed to avoid unnecessary computation. The code has been fully translated into English\n",
    "for reproducibility, and the stored outputs do not affect the functioning of the notebook."
   ],
   "metadata": {
    "id": "SDFryMiPETqh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4680,
     "status": "ok",
     "timestamp": 1765275415407,
     "user": {
      "displayName": "Tamara Perez Perez",
      "userId": "04594035506562290230"
     },
     "user_tz": -60
    },
    "id": "9mLkhkqLzSwO",
    "outputId": "014ebbda-f54a-421f-b3c3-46a972979cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  9 10:16:52 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   34C    P0             52W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "GPU Detectada: NVIDIA A100-SXM4-80GB\n",
      "VRAM Total: 85.17 GB\n"
     ]
    }
   ],
   "source": [
    "# GPU information (if available)\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    total_vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"Detected GPU: {device_name}\")\n",
    "    print(f\"Total VRAM: {total_vram:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU detected. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11549,
     "status": "ok",
     "timestamp": 1766071773291,
     "user": {
      "displayName": "Tamara Perez Perez",
      "userId": "04594035506562290230"
     },
     "user_tz": -60
    },
    "id": "tic4ObaaKQft",
    "outputId": "fec73eca-5a5a-4e1f-a2c5-244cf4e99752"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset loaded: (74759, 21) rows\n",
      "Columns: ['review_text', 'review_en', 'rating', 'date', 'user_total_reviews', 'user_id', 'is_local_guide', 'lang', 'park_name', 'text_length', 'year', 'month', 'quarter', 'month_name', 'season', 'gender', 'text_bert', 'text_stats', 'text_en_clean', 'topic_id', 'topic_label']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset generated in Notebook 4\n",
    "df = pd.read_pickle(INPUT_FILE)\n",
    "print(f\"Dataset loaded: {df.shape} rows\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1766071776741,
     "user": {
      "displayName": "Tamara Perez Perez",
      "userId": "04594035506562290230"
     },
     "user_tz": -60
    },
    "id": "aZFMuz5TxIhN",
    "outputId": "2f14475f-979a-429f-e6c3-31de87882641"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74759 entries, 0 to 74758\n",
      "Data columns (total 21 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   review_text         74759 non-null  object             \n",
      " 1   review_en           74759 non-null  object             \n",
      " 2   rating              74759 non-null  int64              \n",
      " 3   date                74759 non-null  datetime64[ns, UTC]\n",
      " 4   user_total_reviews  74759 non-null  int64              \n",
      " 5   user_id             74759 non-null  object             \n",
      " 6   is_local_guide      74759 non-null  bool               \n",
      " 7   lang                74759 non-null  object             \n",
      " 8   park_name           74759 non-null  object             \n",
      " 9   text_length         74759 non-null  int64              \n",
      " 10  year                74759 non-null  int32              \n",
      " 11  month               74759 non-null  int32              \n",
      " 12  quarter             74759 non-null  int32              \n",
      " 13  month_name          74759 non-null  object             \n",
      " 14  season              74759 non-null  object             \n",
      " 15  gender              74759 non-null  object             \n",
      " 16  text_bert           74759 non-null  object             \n",
      " 17  text_stats          74759 non-null  object             \n",
      " 18  text_en_clean       74759 non-null  object             \n",
      " 19  topic_id            74759 non-null  int64              \n",
      " 20  topic_label         74759 non-null  object             \n",
      "dtypes: bool(1), datetime64[ns, UTC](1), int32(3), int64(4), object(12)\n",
      "memory usage: 10.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890,
     "referenced_widgets": [
      "9c78423be06d48198a49d7991fc555d5",
      "767344a290694e1b87f10aeb628f1783",
      "701d6cfdd30b41dfb0feb68abf0c3567",
      "0ffa128427cb427699dd7a9ef05c92c1",
      "f8450f97b66f41ac8e2e24be28bcadcc",
      "01ec4faf544e4063b9acd09983a172f0",
      "3dc084d9f45c45359d009df775ca1b12",
      "83103d27fdbe4c6a9e70b84377b7b57b",
      "49a56e8fcb284f51a0ae02163c5e3b7f",
      "9b22e8773ff042448bf80e8b893181b2",
      "5a1943bbdac5409bbd020fff1d2ddb51",
      "e188e7cb60aa4cceb8118f98128b50c5",
      "db419dbc98ce4025ae295cf0b10c6c51",
      "e36b051f73a041c7b984464b9901be3a",
      "5460b2ee716c4e18b2f10ad655b6ef63",
      "faf564f72fcc4d538ee07c62076f8053",
      "efef983a5ed54f4484b449ccec195500",
      "8a72cbf0624845ecb323a035db65c0cb",
      "76b048656c094fa99f418e922e2d54bc",
      "d64c5ad4c28246ca9f4a72c3a66a3c4b",
      "5ff4a298d2744a83b5cd896427c9d94d",
      "7bd609b077c84566ba2cd1aeeff089a9",
      "f7feca4b79f24542945a5a4bde42b66f",
      "981316bbe46d4d5eaba2949bb22321bb",
      "925cf77a602a425d97ea90d315da65ae",
      "49549561198644a495c19cf1e0d9dde4",
      "ac6432a278a14d8c94ab54d7f018c5a9",
      "3f17c36753174edf8e0e21b7b470253b",
      "fa65dd21e98d4fa6ba36987677072da0",
      "4eccf13e614547e9b2765195f8c38c60",
      "c3e6b118402e4c029b234ea1b4dc9bbe",
      "58c2f32afdaa494795bd2ad626b21edf",
      "3a1f6b153e564e9a9e036146a2f5570c",
      "b921400d5c0e4021997076c10540b47d",
      "d997c5eb57964ce2a19d9f7b0bbf58b4",
      "0ae404d044274ebf9e0ea182c8f24bc6",
      "b05d9ea697ef4ee5a04c19c2af379a96",
      "d88b99f425984c07b637cf15cca58846",
      "077cc28f79ed4217a858ce6818813f9b",
      "1d988ef3048e42faa5fad0087f3d3b23",
      "0dbda6369aec4c13835b10f968ac3b40",
      "f8c1a82928be47919a78d26aceb858d8",
      "ecae0331860b4b32b982dd05d758d0cf",
      "e6a03b1a3b6a46168fe26f3eaf86c477",
      "14cd513f0ef24fc8a30447c4d502749a",
      "6e866a5996ad4e9f9d1c92680c0760c2",
      "df7a8781ef61474899089ce46f8af7d8",
      "42139c7197a14f05b9ff428a598a17f7",
      "c953db1825b84d4089c2d9d07e3f8bad",
      "193f7d5e95094eeaba23e942b3613f1f",
      "8f3fbc8ba0c44f41832766bfb437530d",
      "b1b3297ca6ae45a18b77d93bc4df10de",
      "120a3888f82d4b6d8f901f7b323f840a",
      "aced6d2a87da445b99cdfdbdbe356ca4",
      "b0d7dfe24ac64142a1337787fb0f9a27",
      "6ae310ec75354228ac5cb46d3db39a95",
      "f88aca5d2e8a4cb480dd0bf534a8c3df",
      "49434ed4e1a848a48e66341ca6a4bad3",
      "fcc176d7298d49a1ad4dae8ef5ca2f22",
      "4fb202d0e8884ca394333e26b791f88f",
      "dc0f32e7ba674843bef7361b78699f77",
      "8e64ac5b58ec4cb39856609a6b560bf0",
      "cc2ea1e3d33549e4b62f78819fa085c3",
      "76c6ef8ecc2a4ad0ad96b19ee92bf35b",
      "18e97c9aad484c79ab90b33fd19b7aaf",
      "cd99cbcf4c224f3bbf2f94dde1dd1542",
      "4a27a2c2fa0d457e884c1f8edd0f8b49",
      "b8d46057baa5403c88db1a2c404607ca",
      "7aead659dcc646bf8cd170347291b6cc",
      "25ff245aa50f4e4c9460d54c9e7c24cb",
      "07c994e8c1d84403a3d0b22378d3b0cd",
      "11318ecbe9c04d049d6c61998ca24d17",
      "5f33caa026be4763af42737f595ac473",
      "e98e695e230a413ea4d6617056deadfe",
      "183d5dbe5e8343f1a92525ae30e8f4b4",
      "aa5188409f4649ec84a08e4ac7476963",
      "1c259615c3294449863d513a8e9d16c9",
      "48f06bfbfe8b4d5b9dfa4ea12dbae11f",
      "21ab71f31c1b4908ada1f2f033593371",
      "14ea4b5020b74b0c9d63edd9e8b0e8ee",
      "728fcda0e4e84795b7794157e10f2b07",
      "0af48829405a42ec98ba9b1096635930",
      "fcb3e9921b994afbbaa2d8d226b832fc",
      "90e9aec707834e9aae0a6a9661ed8a51",
      "3f5c7a42db4b4ec5a14e85af3f572078",
      "5581de10d55e4c70bd22b33a1eb46654",
      "d459ea260a154bc39b03f1a2b44cbae2",
      "5a425b43a907445f93d9d8dc81df19f4",
      "dccd90b9294e49c191ae0c43469c00d8",
      "3c115d4ed89042d784d884eebc4fbf3e",
      "04a0f2a8af8545f09dc8cca261a7094c",
      "3f21af294e11463a85db04ea0f748866",
      "ac7e4607445f4a848f56f312535700ac",
      "5ba82a934ef948889df34099ddf3bf9a",
      "83f6ead3224c4ea8827b997bdb732a9d",
      "9bd8f394fbf2445885d672894831deeb",
      "c5cc1031cbe34fe480dd477cf133c677",
      "fc99aa7c142c499188c84ae42ad25acd",
      "9f75d00f81a74d73a5dd7ed54d321eee",
      "8d40fd63b520426fb5ee1b66162a0756",
      "0f2913d988b0469b82050531ae709f3e",
      "cd47c0921a344cd4be006a6db2897f1a",
      "c720031b5b964f6d9d3c1644ace8292b",
      "408432c9e9454a68bc1b6d5e7926854d",
      "4fa9219a22474347abb53237b3667971",
      "c849e8ef1c5b4d5c9af26248e5d867ad",
      "71a3509beaec4eddb700457cfb5ebdb9",
      "240596afe1b448bba19084c6caaf8ae7",
      "6076a43dcb7e45c4adc5c29bdae57f29",
      "3b48f2addb7447b2b2dc015ced566f70",
      "83d97dde539a45f5942ff00f72981199",
      "408b3e569cfa4e2f9bf17c3bc198f7e2",
      "85806c4d312e40989b71a46881d8c88a",
      "dc15c3f4caa3456ba30d353f9c3b7357",
      "92f54eb71fd04bc9889203a6fdad9186",
      "d4661c0a59d04a6da54b139dd90accd5",
      "b3fc42dfc11b40ae9f1f069e4e112752",
      "370fa55718194ae1bad65a362d47c52f",
      "45af2ed3a09b4f509b12531ad9d3f3bf",
      "bb91f523fc074340a55e13c9cb1c8951",
      "29bd7f6324864ee8bce4e9cb111edcf1",
      "bb30e9d4bdbe469f86d62cb3c9246be4",
      "6356722caab647b0b8f324d7b9461f4e",
      "e50dc2ed765b4ba7a415421b6dc3887e",
      "c6eb5356fc5c41ef8506a339d187dd06",
      "c0e33340de664d99ad014e1af55be684",
      "12755b4e28bf46188edac64531e153da",
      "ba91048c9023476b942a3e86e2ef9b4c",
      "774bde99f5ba442bbad9fd7ab9501553",
      "a9b486bb19074ed3bd8338d4d7f6951f",
      "ff1724f417a849adaf957baf9ecd3afc",
      "eac1ec2b12eb405c8248bf9cee6b553c",
      "6a077d3b2f584beb912b9bc5fe65839c",
      "15092c3e018046bc9b58535cdbfeb1e2",
      "f6eb46a3a7f64803ae277fa1a7538892",
      "5f9f1b26dd054647bf8df0856ab81b6f",
      "7c5bc286df604b51926b58edd40ed290",
      "cab472789e674d32a98631629e610aba",
      "50e306eada99427cac202b194a2d9e98",
      "0219d40a16f04e1a9dd2db2e47114c2e",
      "471aa7892d784482b9487b5ab7246f62",
      "bcdacddcda594e768c018eecb8cedb5e",
      "05a1cb71297e4369beb35435fad43621",
      "1f11b6abd35b41128b43e65af1fae07d",
      "eb1e8ec4b0fc4995926b4f22d3581939",
      "c743f26195444a14b8bed7b344a84706",
      "124363dc0c1a44abb578d2e77f3df5ce",
      "0a0e0cdca6ff4c598328878369ae1b7f",
      "deeaacac319143249ff279e0780038ae",
      "27dee0f484e748edb1060e7771a0a925",
      "26dfce9699bd4b5ba78b230b81bcd559",
      "382a211e4c294deabaf93ddafdba89da",
      "1d910c9e54c143c9a15d1618cda065e2",
      "64f19e313c9045868505b38830793ba0",
      "a340055b2d6d41b783e35acfcd2e9392",
      "7bad7c90b7f04c9eab0216a6b32c8332",
      "22a18cb3e412404ab39836535baa4883",
      "61297f0774ad40b1899a7dcc2c5d7632",
      "9b2d6ca0c5f346c2a586b0cff4afff41",
      "eb891b067cc04adf8e0bcbc62fe743fe",
      "22f39d44de34457e9034772ad2a4759c",
      "8af670ee882244edabacdc02f6c8669a",
      "16ca568667e14a4cba3d8097898a5bad",
      "2b55e07ecf6246b4930c59b7d44da3fa",
      "ee6f19b424d642a8a310befa2bba3e00",
      "fdf2b94c91934a9da7f8acc45c010835",
      "2e7c4aaa8cff4b429d5b9a10a3bf5bef",
      "34e0c13bb2564914b524c8fd2edc2bfd",
      "e1aa3d37640c438eb4cdf5042dcf8ef0",
      "1c3f5959a8864a6da39434cd819094c7",
      "ed765fc975814f7db45463b224c01054",
      "c47d06c85225441aa1b5aee86c8ff33c",
      "6952d2368d9541c1b2f7ab59b39eb78e",
      "265247c17a1f4bedb4ffbdab86d7bb7e",
      "199ec119dd7f49a1b174200fb99aabd5",
      "2c354075ef5349a0b7c994eb5c765826",
      "608650e36cd14f5d960e2c7b460b4a11",
      "c8c728f1c8bd448e95b2a4db62cb5bb4",
      "516700f1b6ce48a0ad2800f5362e9ac0",
      "8dec3a0171024e73bb0df320444eb9f8",
      "04aa8b2288fd4906bb4a84d725955f7d",
      "997e6590ce9f4868a14ae0095e0027c6",
      "d4cf791fdb654a24b564e290951e751f",
      "9d8b97a0701f40328d0b29649d09151a",
      "a0db72c49035403180fcf66bde87738b",
      "a661722d45fe4444bbe607d04e5afafa",
      "80b6f8697e7e464ab19f05408916f845",
      "d43c1eddb9624631a019643a2e20c383",
      "b469771e28cd44acbd2a67133c7e8243",
      "2c7b156e894743c99440dcba359e81a1",
      "43cde2aaf4d9459f93622c37166357de",
      "da3c9c371219483faf085b2569b91289",
      "fe1a5d0cb724416b9e8cf39928ccbf93",
      "df3eee2c4f264639913b145bcd97901d",
      "04532b9b0187468c8e0ab78282a59bf0",
      "6fac9a6297424d668c86028f72a0f30a",
      "ec4c2b9c721a4e71a5b7c8ce5384d462",
      "2fef62933d9644a3ae3a959ed95ec647"
     ]
    },
    "executionInfo": {
     "elapsed": 36774,
     "status": "ok",
     "timestamp": 1765275708707,
     "user": {
      "displayName": "Tamara Perez Perez",
      "userId": "04594035506562290230"
     },
     "user_tz": -60
    },
    "id": "qss84cuIOnSR",
    "outputId": "e246ecff-8576-4958-c03d-f5524aa8405c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c78423be06d48198a49d7991fc555d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e188e7cb60aa4cceb8118f98128b50c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7feca4b79f24542945a5a4bde42b66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b921400d5c0e4021997076c10540b47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cd513f0ef24fc8a30447c4d502749a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae310ec75354228ac5cb46d3db39a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/759 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a27a2c2fa0d457e884c1f8edd0f8b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f06bfbfe8b4d5b9dfa4ea12dbae11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/373 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccd90b9294e49c191ae0c43469c00d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d40fd63b520426fb5ee1b66162a0756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d97dde539a45f5942ff00f72981199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb30e9d4bdbe469f86d62cb3c9246be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/982 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a077d3b2f584beb912b9bc5fe65839c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f11b6abd35b41128b43e65af1fae07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a340055b2d6d41b783e35acfcd2e9392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf2b94c91934a9da7f8acc45c010835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608650e36cd14f5d960e2c7b460b4a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43c1eddb9624631a019643a2e20c383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos cargados correctamente:\n",
      " - nlptown_5stars\n",
      " - distilbert_multi\n",
      " - xlmr_twitter_multi\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Dictionary to store all sentiment-analysis models\n",
    "models = {}\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Model 1: Multilingual BERT (predicts 1\u20135 star ratings)\n",
    "models[\"bert_5stars\"] = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    tokenizer=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Model 2: Multilingual DistilBERT (negative / neutral / positive)\n",
    "models[\"distilbert_multilingual\"] = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
    "    tokenizer=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
    "    return_all_scores=False\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Model 3: XLM-RoBERTa multilingual (negative / neutral / positive)\n",
    "models[\"xlmr_twitter\"] = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual\",\n",
    "    tokenizer=\"cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual\",\n",
    "    return_all_scores=False\n",
    ")\n",
    "\n",
    "print(\"Models successfully loaded:\")\n",
    "for name in models:\n",
    "    print(\" -\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Nav93DNOnXi"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Convert a 1\u20135 star rating into a three-class polarity label\n",
    "def map_stars_to_sentiment(stars):\n",
    "    if stars <= 2:\n",
    "        return \"negative\"\n",
    "    elif stars == 3:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "# Basic preprocessing to ensure the input text is a valid string\n",
    "def _preprocess_text(t):\n",
    "    if not isinstance(t, str):\n",
    "        return \"\"\n",
    "    return t.strip()\n",
    "\n",
    "# Unified sentiment prediction function for all loaded models\n",
    "def predict_sentiment(text, model_key):\n",
    "    text = _preprocess_text(text)\n",
    "\n",
    "    # Assign neutral sentiment for empty inputs\n",
    "    if text == \"\":\n",
    "        return \"neutral\"\n",
    "\n",
    "    clf = models[model_key]\n",
    "\n",
    "    # Inference with safe truncation for long inputs\n",
    "    result = clf(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    res = result[0] if isinstance(result, list) else result\n",
    "    label = res.get(\"label\", \"\")\n",
    "    label_lower = label.lower()\n",
    "\n",
    "    # Special case: the nlptown model returns labels like \"1 star\", \"5 stars\", etc.\n",
    "    if model_key == \"bert_5stars\":\n",
    "        match = re.search(r\"(\\d)\", label_lower)\n",
    "        if match:\n",
    "            stars_pred = int(match.group(1))\n",
    "            return map_stars_to_sentiment(stars_pred)\n",
    "        return \"neutral\"\n",
    "\n",
    "    # For all other models, assume standard labels:\n",
    "    # \"negative\", \"neutral\" or \"positive\"\n",
    "    return label_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23486,
     "status": "ok",
     "timestamp": 1765275744100,
     "user": {
      "displayName": "Tamara Perez Perez",
      "userId": "04594035506562290230"
     },
     "user_tz": -60
    },
    "id": "afx59Ea_OnaS",
    "outputId": "95b27bee-7bff-419e-d629-440492b38d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================\n",
      "  Modelo: DistilBERT multiling\u00fce\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.5000    0.7958    0.6141       240\n",
      "     neutral     0.1176    0.0146    0.0260       137\n",
      "    positive     0.8270    0.7978    0.8121       623\n",
      "\n",
      "    accuracy                         0.6900      1000\n",
      "   macro avg     0.4815    0.5361    0.4841      1000\n",
      "weighted avg     0.6513    0.6900    0.6569      1000\n",
      "\n",
      "\n",
      "===========================================================\n",
      "  Modelo: XLM-RoBERTa Twitter multiling\u00fce\n",
      "===========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.5167    0.9042    0.6576       240\n",
      "     neutral     0.2087    0.1752    0.1905       137\n",
      "    positive     0.9333    0.6966    0.7978       623\n",
      "\n",
      "    accuracy                         0.6750      1000\n",
      "   macro avg     0.5529    0.5920    0.5486      1000\n",
      "weighted avg     0.7341    0.6750    0.6809      1000\n",
      "\n",
      "\n",
      "===========================================================\n",
      "  Modelo: BERT multiling\u00fce 1\u20135 estrellas (nlptown)\n",
      "===========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6743    0.8542    0.7537       240\n",
      "     neutral     0.3642    0.4015    0.3819       137\n",
      "    positive     0.9284    0.8122    0.8664       623\n",
      "\n",
      "    accuracy                         0.7660      1000\n",
      "   macro avg     0.6557    0.6893    0.6674      1000\n",
      "weighted avg     0.7902    0.7660    0.7730      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ground truth label derived from the numeric rating\n",
    "df[\"sentiment_true\"] = df[\"rating\"].apply(map_stars_to_sentiment)\n",
    "\n",
    "# Subsample to reduce computational cost\n",
    "df_sample = df.sample(1000, random_state=42).copy()\n",
    "\n",
    "# Models to evaluate: (model_key, descriptive_label)\n",
    "models_to_evaluate = [\n",
    "    (\"distilbert_multilingual\", \"DistilBERT Multilingual\"),\n",
    "    (\"xlmr_twitter\", \"XLM-RoBERTa Twitter Multilingual\"),\n",
    "    (\"bert_5stars\", \"Multilingual BERT (1\u20135 stars)\")\n",
    "]\n",
    "\n",
    "for model_key, model_label in models_to_evaluate:\n",
    "    print(\"\\n===========================================================\")\n",
    "    print(f\"  Model: {model_label}\")\n",
    "    print(\"===========================================================\")\n",
    "\n",
    "    pred_col = f\"pred_{model_key}\"\n",
    "\n",
    "    # Sentiment prediction for the current model\n",
    "    df_sample[pred_col] = df_sample[\"text_bert\"].apply(\n",
    "        lambda t: predict_sentiment(t, model_key)\n",
    "    )\n",
    "\n",
    "    # Filter valid predictions\n",
    "    mask = df_sample[pred_col].notna()\n",
    "    y_true = df_sample.loc[mask, \"sentiment_true\"]\n",
    "    y_pred = df_sample.loc[mask, pred_col]\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWBsD5v5_33o"
   },
   "outputs": [],
   "source": [
    "# Directory for intermediate checkpoints\n",
    "CHECKPOINT_DIR = MODELS_DIR / \"bert_nlptown_checkpoints\"\n",
    "\n",
    "# Directory for the final fine-tuned model (used later for inference)\n",
    "FINAL_MODEL_DIR = MODELS_DIR / \"bert_nlptown_finetuned_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612,
     "referenced_widgets": [
      "68996c68e5d44a63a96c322d4ad5232a",
      "87d628e643964c588e6483f636f8c557",
      "dfc1758eb2fe470bb6143b5b9b6c091d",
      "e218cd1a02314e38925815c4f3c98dce",
      "c0370d004bd243abbf50f284f54bc0b7",
      "ce51c978534e4145be103ba76d41e4a7",
      "7f68af6bb1934cc78b6ef650ef3f3886",
      "67a1f709489e4c20aed539c9f462a222",
      "3193bd4f0f0b43e6abf7ba35127217c9",
      "0bc0d01b81df47b1b4d425eda33f682e",
      "ab48495491384f8380593f5ec26af8ee",
      "92ad1a87f9aa40bab74776610f53de52",
      "8adaf96432b146ae8c33573939e0424c",
      "02f67fe3f1964922b0be24f45449cf4c",
      "737fdf6ff64e423abf735a1b0f01b398",
      "ab1e2ccd3dab481d8c4a52ae02856c59",
      "56ce4bed9f904993b88a978178451374",
      "504a8d8d016948e38ef87a3fe93d6c06",
      "54021dd4e67d465990a6800d691a86cb",
      "e28c45fb77eb4ea0b78354e1a34fa6c8",
      "e5447e2da8e444a8936b9d9fc5e0a9a6",
      "19c7c597cc594a13b1ba212d38f8715a",
      "c644039af69e4a52a3e7d666b6ff455d",
      "989ae8a8bba44469bc1e7db8993862dc",
      "6a89f111d2f3446fb973d8cf27a6d251",
      "abe6c7465c4e4a6894d97f6dcbc77096",
      "c6c00da212d64742bb2522bbbd9feac7",
      "3e16d1a42267488aaa297e6c6f6eb4e8",
      "b570dd105c964b40b99285af620b8148",
      "5f8d0457ed5e4199a880cc680924d4d3",
      "7e30a63dffaf47febe202a39197527ad",
      "68a9605957444bca9281e9f1d427c130",
      "96e9c50b2ce6421c9d2ef7603e133c71"
     ]
    },
    "executionInfo": {
     "elapsed": 768434,
     "status": "ok",
     "timestamp": 1765277342576,
     "user": {
      "displayName": "Tamara Perez Perez",
      "userId": "04594035506562290230"
     },
     "user_tz": -60
    },
    "id": "jFdsILLf-ibf",
    "outputId": "efbd8c3d-4676-4182-cf71-0fe677b8071b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:127: SyntaxWarning: invalid escape sequence '\\E'\n",
      "<>:127: SyntaxWarning: invalid escape sequence '\\E'\n",
      "/tmp/ipython-input-1203385529.py:127: SyntaxWarning: invalid escape sequence '\\E'\n",
      "  print(f\"\\Entrenamiento finalizado en {minutes} minutos y {seconds} segundos\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Preparando el dataset (Train / Val / Test)...\n",
      "Tama\u00f1os finales -> Train: 52361, Val: 11184, Test: 11214\n",
      "2. Tokenizando...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68996c68e5d44a63a96c322d4ad5232a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52361 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ad1a87f9aa40bab74776610f53de52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c644039af69e4a52a3e7d666b6ff455d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Cargando modelo base...\n",
      "4. Iniciando entrenamiento en GPU A100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1203385529.py:102: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando cron\u00f3metro...\n",
      "Entrenando modelo (Paciencia: 3 \u00e9pocas)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13092' max='32730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13092/32730 12:29 < 18:44, 17.46 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.834479</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.632448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.808900</td>\n",
       "      <td>0.875229</td>\n",
       "      <td>0.639306</td>\n",
       "      <td>0.631296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.711400</td>\n",
       "      <td>0.929928</td>\n",
       "      <td>0.640558</td>\n",
       "      <td>0.631321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.611500</td>\n",
       "      <td>0.997314</td>\n",
       "      <td>0.626431</td>\n",
       "      <td>0.623112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Entrenamiento finalizado en 12 minutos y 30 segundos\n",
      "5. Guardando modelo final...\n",
      "Fine-tuning completado. Modelo guardado en: /content/drive/MyDrive/UOC/Master en Ciencia de Datos/2025.1/TFM/TFM_Analisis_Reviews_Parques_Tematicos/04_Models/bert_nlptown_finetuned_v1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "\n",
    "# ============================================================\n",
    "# 1. Dataset preparation\n",
    "# ============================================================\n",
    "print(\"Preparing dataset splits (train/val/test)...\")\n",
    "\n",
    "df_tuning = df[['text_bert', 'rating']].copy()\n",
    "df_tuning['label'] = df_tuning['rating'] - 1  # Convert to 0\u20134 scale\n",
    "\n",
    "# Step 1: Hold-out test set (15%)\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df_tuning,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=df_tuning['label']\n",
    ")\n",
    "\n",
    "# Step 2: Train/Validation split inside remaining 85%\n",
    "# Validation should represent ~15% of the total dataset \u2192 0.15 / 0.85 \u2248 0.176\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=0.176,\n",
    "    random_state=42,\n",
    "    stratify=train_val_df['label']\n",
    ")\n",
    "\n",
    "print(f\"Final sizes \u2192 Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"validation\": Dataset.from_pandas(val_df),\n",
    "    \"test\": Dataset.from_pandas(test_df)\n",
    "})\n",
    "\n",
    "# ============================================================\n",
    "# 2. Tokenization\n",
    "# ============================================================\n",
    "print(\"Tokenizing dataset...\")\n",
    "\n",
    "model_checkpoint = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text_bert\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Model and metrics\n",
    "# ============================================================\n",
    "print(\"Loading base model...\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=5\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# ============================================================\n",
    "# 4. Fine-tuning\n",
    "# ============================================================\n",
    "print(\"Starting fine-tuning on GPU...\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(CHECKPOINT_DIR),\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"Training started...\")\n",
    "\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Training completed in {int(elapsed // 60)} min {int(elapsed % 60)} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438,
     "referenced_widgets": [
      "21b08c41531347ebb62b3e3dbde600b0",
      "8b46ffaa9a7e46b69ba3ac994513dd0d",
      "c9e988d45fef400f9a343a6feb0272fc",
      "8620d5c96dbd497681b9432fe3d58b8d",
      "9ab983176be44761a7ccc721cc1013b0",
      "94deba4b9ea54b67ae07aaecd47c1996",
      "2df905fc75c14978bed6ec1cd316fe3a",
      "f8f867c6171e45f485838d215dd64bfe",
      "7574c25333e146eba01faede84dda4f1",
      "04aff908e0354106b509c5ca6e88310c",
      "0517c87a55f34e068a2387554b5180cd"
     ]
    },
    "executionInfo": {
     "elapsed": 262415,
     "status": "ok",
     "timestamp": 1765278098204,
     "user": {
      "displayName": "Tamara Perez Perez",
      "userId": "04594035506562290230"
     },
     "user_tz": -60
    },
    "id": "tXcdTdWu-ikD",
    "outputId": "7d017bb2-48d5-412b-a37c-1f4346059b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta del modelo (Local): /content/drive/MyDrive/UOC/Master en Ciencia de Datos/2025.1/TFM/TFM_Analisis_Reviews_Parques_Tematicos/04_Models/bert_nlptown_finetuned_v1\n",
      "Tokenizador base (Hugging Face): nlptown/bert-base-multilingual-uncased-sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y Tokenizador cargados correctamente\n",
      "Reconstruyendo la separaci\u00f3n usando random_state=42...\n",
      "Etiquetando filas en el DataFrame principal...\n",
      "Distribuci\u00f3n recuperada\n",
      "dataset_split\n",
      "train         52361\n",
      "test          11214\n",
      "validation    11184\n",
      "Name: count, dtype: int64\n",
      "Reconstrucci\u00f3n exitosa\n",
      "\n",
      "Iniciando cron\u00f3metro...\n",
      "Procesando 74759 registros en NVIDIA A100...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b08c41531347ebb62b3e3dbde600b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74759 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencia completada en 4m 17s.\n",
      "Mapeando resultados...\n",
      "\n",
      "Dataset guardado en: /content/drive/MyDrive/UOC/Master en Ciencia de Datos/2025.1/TFM/TFM_Analisis_Reviews_Parques_Tematicos/02_Data/05_dataset_sentiment_topics.csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================\n",
    "# 1. Model and path configuration\n",
    "# ============================================================\n",
    "local_model_path = str(FINAL_MODEL_DIR)\n",
    "base_tokenizer_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "print(f\"Model path: {local_model_path}\")\n",
    "print(f\"Tokenizer source: {base_tokenizer_name}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Load fine-tuned model and tokenizer\n",
    "# ============================================================\n",
    "try:\n",
    "    loaded_model = AutoModelForSequenceClassification.from_pretrained(local_model_path)\n",
    "    loaded_tokenizer = AutoTokenizer.from_pretrained(base_tokenizer_name)\n",
    "    print(\"Model and tokenizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    raise e\n",
    "\n",
    "sentiment_pipeline = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=loaded_model,\n",
    "    tokenizer=loaded_tokenizer,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3. Reconstruct dataset split (train/val/test)\n",
    "# ============================================================\n",
    "print(\"Reconstructing dataset split (random_state=42)...\")\n",
    "\n",
    "stratify_col = df[\"rating\"] if \"rating\" in df.columns else None\n",
    "\n",
    "# Phase 1: train+val vs. test\n",
    "ids_train_val, ids_test = train_test_split(\n",
    "    df.index,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=stratify_col\n",
    ")\n",
    "\n",
    "# Phase 2: train vs. validation\n",
    "stratify_sub = df.loc[ids_train_val, \"rating\"] if stratify_col is not None else None\n",
    "\n",
    "ids_train, ids_val = train_test_split(\n",
    "    ids_train_val,\n",
    "    test_size=0.176,\n",
    "    random_state=42,\n",
    "    stratify=stratify_sub\n",
    ")\n",
    "\n",
    "df[\"dataset_split\"] = \"unassigned\"\n",
    "df.loc[ids_train, \"dataset_split\"] = \"train\"\n",
    "df.loc[ids_val, \"dataset_split\"] = \"validation\"\n",
    "df.loc[ids_test, \"dataset_split\"] = \"test\"\n",
    "\n",
    "print(\"Split distribution:\")\n",
    "print(df[\"dataset_split\"].value_counts())\n",
    "\n",
    "# ============================================================\n",
    "# 4. Inference on full dataset\n",
    "# ============================================================\n",
    "print(f\"\\nRunning inference on {len(df)} samples...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "input_texts = df[\"text_bert\"].tolist()\n",
    "raw_predictions = []\n",
    "\n",
    "# Manual batching because HF pipeline does not stream batches\n",
    "batch_size = 128\n",
    "for i in tqdm(range(0, len(input_texts), batch_size)):\n",
    "    batch = input_texts[i:i + batch_size]\n",
    "    outputs = sentiment_pipeline(\n",
    "        batch,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    raw_predictions.extend(outputs)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Inference completed in {int(elapsed // 60)}m {int(elapsed % 60)}s.\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. Post-processing\n",
    "# ============================================================\n",
    "print(\"Mapping predictions...\")\n",
    "\n",
    "def extract_rating(pred):\n",
    "    \"\"\"Extract numeric score from labels such as '3 stars'.\"\"\"\n",
    "    label = pred[\"label\"].lower().strip()\n",
    "    num = label.split(\" \")[0]\n",
    "    return int(num)\n",
    "\n",
    "def map_sentiment(r):\n",
    "    \"\"\"Map 1\u20135 star score into sentiment classes.\"\"\"\n",
    "    if r <= 2:\n",
    "        return \"negative\"\n",
    "    if r == 3:\n",
    "        return \"neutral\"\n",
    "    return \"positive\"\n",
    "\n",
    "df[\"predicted_rating\"] = [extract_rating(p) for p in raw_predictions]\n",
    "df[\"final_sentiment\"] = df[\"predicted_rating\"].apply(map_sentiment)\n",
    "\n",
    "# ============================================================\n",
    "# 6. Export\n",
    "# ============================================================\n",
    "pkl_path = PROCESSED_DIR / \"05_dataset_sentiment_topics.pkl\"\n",
    "df.to_pickle(pkl_path)\n",
    "\n",
    "print(f\"Dataset exported to: {pkl_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "authorship_tag": "ABX9TyN/FRScTZOekZ16Iv23BTxk"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}